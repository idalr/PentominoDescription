{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview ###\n",
    "\n",
    "This notebook is divided into the following section:\n",
    "- TakeCV corpus\n",
    "    - Pre-annotation Preprocessing\n",
    "    - Pos-annotation Preprocessing\n",
    "- Survey corpus\n",
    "    - Preprocessing\n",
    "    \n",
    "**TakeCV corpus** is a sub-corpus, a part of the ***PentoRef*** (Zarrieß et al., 2016). It consists of monologues of Human agent describing verbally a pentomino piece in German to a wizard, which has to correctly identify the piece in the real-world scene.\n",
    "- In the pre-annotation step, we removed the non-verbal transcription and translate the verbal description to English with DeepL.\n",
    "- In the annotation step, we manually identify the labels of each pentomino piece, along with the color, shape, position, scene ID, and recheck the machine translated utterance. After that, we do a short data survey on label.\n",
    "\n",
    "**Survey corpus** is our own data, collected from a closed survey. Participants were asked to type down the description of a pentomino piece they saw in the real-world scene. Here, we also clean the data and do a short data survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TakeCV corpus\n",
    "## Pre-annotation Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/deepl/\n",
    "#pip install deepl\n",
    "import deepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need authen key from free deepl api account # up to 500k char/month\n",
    "auth_key = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx:xx\"  \n",
    "translator = deepl.Translator(auth_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['takecv_r1.xlsx',\n",
       " 'takecv_r2.xlsx',\n",
       " 'takecv_r3.xlsx',\n",
       " 'takecv_r4.xlsx',\n",
       " 'takecv_r5.xlsx',\n",
       " 'takecv_r6.xlsx',\n",
       " 'takecv_r7.xlsx',\n",
       " 'takecv_r9.xlsx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "xlsx_files = os.listdir(path+'\\\\raw\\\\')\n",
    "xlsx_files # importing from excel allows vowels with umlaut, but csv could not read them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring data from one of the file\n",
    "\n",
    "# importing from excel allows vowels with umlauts, but csv could not read them\n",
    "df = pd.read_excel('raw/takecv_r5.xlsx').iloc[:, 0].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing steps**\n",
    "\n",
    "* everything inside <v=\"...\"> should replace the one in <v=\"...\">...\\</v>\n",
    "* if between \\<p> and \\</p> then extract it\n",
    "* everything else inside <...> <.../> </...> {...} can be deleted\n",
    "* clean out anything which isn't A-Za-z0-9()-+\n",
    "* when two utterances belong to the same ( + ), deal with them in the later stage\n",
    "* translate to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_df(df):\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        \n",
    "        text = row[1][3]\n",
    "        t1 = re.sub('<v=\"\"(.+?)\"\">(.+?)</v>',r'\\1', text) # get the right word from the spoken variants\n",
    "        t2 = re.sub('<p>(.+?)</p>',r'\\1', t1) # get rid of marks in partial words\n",
    "        t3 = re.sub(r\"\\{[^()]*\\}\", \"\", t2) # get rid of fillers\n",
    "        t4 = re.sub(r\"\\<[^()]*\\>\", \"\", t3) # get rid of nonverbal markers\n",
    "        t5 = re.sub(r'[^a-zA-Z0-9äöüÄÖÜß\\(\\)\\-\\+\\.\\s]', '', t4) # keep only these letters\n",
    "        if len(t5) > 0:\n",
    "            t6 = translator.translate_text(t5, target_lang=\"EN-US\") # translate with deepL\n",
    "        else: t6 = None\n",
    "    \n",
    "        row[1][4] = t5\n",
    "        row[1][5] = t6\n",
    "        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in xlsx_files:\n",
    "    # read file\n",
    "    df = pd.read_excel('raw/'+f).iloc[:, 0].str.split(',', expand=True)\n",
    "    \n",
    "    # add new columns for cleaned texts and translation\n",
    "    df[4] = df.apply(lambda _: '', axis=1)\n",
    "    df[5] = df.apply(lambda _: '', axis=1)\n",
    "    \n",
    "    #preprocessing\n",
    "    df_clean = preproc_df(df)\n",
    "    \n",
    "    #save to files\n",
    "    df_clean\n",
    "    df_clean.drop([6,7], axis=1).to_excel('takecv'+f[-7:-5]+'_processed.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the 8 annotated files from the folder 'Translation' and combine them into one. Then, we process the text into ['label (pentomino piece's color and shape)','text (piece description)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['takecvr1_processed.xlsx',\n",
       " 'takecvr2_processed.xlsx',\n",
       " 'takecvr3_processed.xlsx',\n",
       " 'takecvr4_processed.xlsx',\n",
       " 'takecvr5_processed.xlsx',\n",
       " 'takecvr6_processed.xlsx',\n",
       " 'takecvr7_processed.xlsx',\n",
       " 'takecvr9_processed.xlsx']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "xlsx_files = os.listdir(path+'\\\\annot_2706\\\\')\n",
    "xlsx_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "takecvr1_processed.xlsx done\n",
      "takecvr2_processed.xlsx done\n",
      "takecvr3_processed.xlsx done\n",
      "takecvr4_processed.xlsx done\n",
      "takecvr5_processed.xlsx done\n",
      "takecvr6_processed.xlsx done\n",
      "takecvr7_processed.xlsx done\n",
      "takecvr9_processed.xlsx done\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('annot_2706/takecvr1_processed.xlsx')\n",
    "print ('takecvr1_processed.xlsx done')\n",
    "\n",
    "for file in xlsx_files[1:]:\n",
    "    read = pd.read_excel('annot_2706/'+file)\n",
    "    df = pd.concat([df, read])\n",
    "    print(file, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={5:'translate', 6:'correct'}).drop(columns=[0,1,2,3,4,'shade','Unnamed: 17'])\n",
    "# r1, r2, r3's idx ranked within the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "translate     228\n",
       "correct      1549\n",
       "color        1168\n",
       "shape        1169\n",
       "up           1169\n",
       "down         1170\n",
       "left         1169\n",
       "right        1169\n",
       "middle       1169\n",
       "scene        1169\n",
       "idx          1169\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no translation, then filter out the row\n",
    "df_filt = df[~df['translate'].isna()] # filter out when no translation or translation correction\n",
    "\n",
    "# filter out lines which are not object description\n",
    "df_filt = df_filt[df_filt['correct']!='x']\n",
    "\n",
    "# if the correct column is empty, then take the value from the translate column\n",
    "df_filt['correct'].fillna(df_filt['translate'], inplace=True) # copy values from translate to correct if correct is empty\n",
    "\n",
    "# fill the cell with the value in the cell above if cell is empty\n",
    "df_fill = df_filt.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "translate    0\n",
       "correct      0\n",
       "color        0\n",
       "shape        0\n",
       "up           0\n",
       "down         0\n",
       "left         0\n",
       "right        0\n",
       "middle       0\n",
       "scene        0\n",
       "idx          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "df_fill.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean color and shape columns\n",
    "df_fill['color'] = df_fill['color'].replace(r'[^a-z]', \"\", regex=True)\n",
    "df_fill['shape'] = df_fill['shape'].replace(r'[^a-z]', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color \n",
      "wooden    453\n",
      "blue      230\n",
      "green     153\n",
      "orange    134\n",
      "yellow    103\n",
      "purple     96\n",
      "gray       88\n",
      "pink       67\n",
      "red        61\n",
      "dtype: int64\n",
      "shape\n",
      "f        148\n",
      "l        126\n",
      "w        126\n",
      "y        124\n",
      "t        119\n",
      "v        117\n",
      "z        117\n",
      "n        113\n",
      "i        112\n",
      "u        106\n",
      "p        101\n",
      "x         76\n",
      "dtype: int64\n",
      "up \n",
      "0.0    951\n",
      "1.0    434\n",
      "dtype: int64\n",
      "down\n",
      "0.0     966\n",
      "1.0     419\n",
      "dtype: int64\n",
      "left\n",
      "0.0     942\n",
      "1.0     443\n",
      "dtype: int64\n",
      "right\n",
      "0.0      908\n",
      "1.0      477\n",
      "dtype: int64\n",
      "middle\n",
      "0.0       789\n",
      "1.0       596\n",
      "dtype: int64\n",
      "scene\n",
      "r3_2     80\n",
      "r3_1     76\n",
      "r1_1     70\n",
      "r1_2     64\n",
      "r4_3     57\n",
      "r2_2     57\n",
      "r4_1     54\n",
      "r3_3     53\n",
      "r7_3     49\n",
      "r2_1     44\n",
      "r7_4     42\n",
      "r7_2     41\n",
      "r4_4     36\n",
      "r6_4     34\n",
      "r6_2     33\n",
      "r7_1     32\n",
      "r7_6     31\n",
      "r6_7     30\n",
      "r7_5     30\n",
      "r5_6     30\n",
      "r6_6     28\n",
      "r4_2     28\n",
      "r9_3     25\n",
      "r6_3     25\n",
      "r5_4     25\n",
      "r6_5     25\n",
      "r5_2     25\n",
      "r5_5     25\n",
      "r5_7     24\n",
      "r5_3     23\n",
      "r5_1     23\n",
      "r9_6     21\n",
      "r6_1     21\n",
      "r5_8     20\n",
      "r9_5     19\n",
      "r9_2     17\n",
      "r2_3     17\n",
      "r9_1     16\n",
      "r9_7     13\n",
      "r9_4     12\n",
      "r9_8     10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check value in each column\n",
    "for col in df_fill.columns[2:-1]:\n",
    "    print (df_fill[[col]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1385, 11)\n"
     ]
    }
   ],
   "source": [
    "df_fill.to_csv('takeCV_concat_2706.csv')\n",
    "print (df_fill.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check lines with translation correction\n",
    "df_fill[df_fill['correct']!=df_fill['translate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill['label'] = df_fill['color'] + ' ' + df_fill['shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any label does not exist\n",
    "target = ['wooden v','blue v','purple n','wooden n','blue z','wooden z',\n",
    "          'green t','yellow t','green w','wooden w','blue i','wooden i',\n",
    "          'yellow u','orange u','pink p','wooden p','red x','wooden x',\n",
    "          'wooden y','gray f','wooden f','wooden l','orange l']\n",
    "\n",
    "# looking for wrongly labeled data\n",
    "to_fix = df_fill[~df_fill['label'].isin(target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# print results if found wrong labels\n",
    "print (to_fix[['scene','label','idx']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1385, 12)\n",
      "(525, 11)\n"
     ]
    }
   ],
   "source": [
    "print (df_fill.shape)\n",
    "\n",
    "df_cat = df_fill.groupby(['label', 'color', 'shape', 'up', 'down', \n",
    "                          'left', 'right', 'middle', 'scene', 'idx'], as_index = False).agg({'correct': ' '.join})\n",
    "\n",
    "#clean correct #punc\n",
    "#clean color/shape #non a-z\n",
    "\n",
    "print (df_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wooden y    39\n",
       "green t     36\n",
       "gray f      33\n",
       "green w     32\n",
       "orange l    32\n",
       "blue i      30\n",
       "red x       30\n",
       "pink p      30\n",
       "blue z      29\n",
       "yellow u    28\n",
       "purple n    28\n",
       "blue v      25\n",
       "yellow t    20\n",
       "wooden v    19\n",
       "orange u    19\n",
       "wooden f    17\n",
       "wooden w    15\n",
       "wooden i    14\n",
       "wooden z    13\n",
       "wooden p    12\n",
       "wooden l    11\n",
       "wooden n    8 \n",
       "wooden x    5 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "label_list = []\n",
    "data_list = []\n",
    "\n",
    "for row in df_cat.iterrows():\n",
    "    label = row[1][0]\n",
    "    text = row[1][-1]\n",
    "    \n",
    "    c_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    c_text = re.sub(r' +',' ', c_text.strip().lstrip())\n",
    "    \n",
    "    #print (c_color, c_shape, c_text)\n",
    "    \n",
    "    text_list.append(c_text)\n",
    "    label_list.append(label)\n",
    "    data_list.append([label, c_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_list\n",
    "#data_df = pd.DataFrame(text_list,label_list).reset_index().rename(columns={'index':'label', 0: 'text'})\n",
    "#data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey Corpus\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('survey_full.xlsx', sheet_name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase and get rid of punctuation marks (except - and \\s)\n",
    "df = data.apply(lambda x: x.astype(str).str.lower()).apply(lambda x: x.astype(str).str.replace('[^a-zA-Z\\-\\s]', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of extra space\n",
    "df['label'] = df['label'].apply(lambda x: re.sub(r' +',' ', x.strip().lstrip()))\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r' +',' ', x.strip().lstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', None)\n",
    "#print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label   \n",
      "blue i      8\n",
      "blue z      8\n",
      "gray f      8\n",
      "green t     8\n",
      "green w     8\n",
      "orange u    8\n",
      "pink p      8\n",
      "purple n    8\n",
      "red x       8\n",
      "wooden l    8\n",
      "wooden v    8\n",
      "wooden y    8\n",
      "dtype: int64\n",
      "label   \n",
      "blue v      8\n",
      "orange l    8\n",
      "orange t    8\n",
      "wooden f    8\n",
      "wooden i    8\n",
      "wooden p    8\n",
      "wooden w    8\n",
      "wooden x    8\n",
      "wooden y    8\n",
      "yellow u    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count label\n",
    "single = df[df['task'] == 'single']\n",
    "scene = df[df['task'] == 'scene']\n",
    "\n",
    "print (single[['label']].value_counts())\n",
    "print (scene[['label']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('processed_survey.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
